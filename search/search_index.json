{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Welcome to Team Bath Hydrobotics' MkDocs This site contains information related to the Software team, our projects and how we operate. This site is built using mkdocs, see more at mkdocs.org .","title":"Home"},{"location":"#overview","text":"","title":"Overview"},{"location":"#welcome-to-team-bath-hydrobotics-mkdocs","text":"This site contains information related to the Software team, our projects and how we operate. This site is built using mkdocs, see more at mkdocs.org .","title":"Welcome to Team Bath Hydrobotics' MkDocs"},{"location":"general/architecture/","text":"The teams goal for 2026 is to enable this architecture Responsibilities of services Preprocesser parse raw sensor data/frames validate and annotate with mission_id, device, ingest_timestamp, schema_version, producer_id smooth or filter eg low pass compute derived metrics (velocity etc) publish to mqtt topics optionally provide rest endpoint for - /health \u2013 system heartbeat /schema \u2013 current telemetry schema (JSON Schema) /status \u2013 CPU/GPU/memory metrics MQTT Broker real time message bus for telemetry and status retain latest message for new subscribers (eg after ui disconnect) Topics such as rov/{rov_id}/{mission_id}/telemetry/{sensor} Allow multiple pub subs Bidirectional communication if necessary (might be for float) Video ingest service capture and encode video stream, stream low latency Avoid routing frames through mqtt, publish metadata to mqtt jetson nano, encode/decode and stream video using ffmpeg allow concurrent subscribers eg UI, recorder optionally provide rest endpoint for - /health \u2013 system heartbeat /schema \u2013 current telemetry schema (JSON Schema) /status \u2013 CPU/GPU/memory metrics Schema registry json schema with pydantic models accessed by fast api retrieve by version and allow ui to request a schema for decoding rather than hard coupling and redefining in all applications UI queries schema registry for data format based on schema present in packets subscribe to cleaned topics via async mqtt clients decode video on seperate thread connect to video ingest service for low latency video show mission critical indicators display tasks lists, timers, alerts potentially allow limited controls input be able to render replay streams offload analysis to dashboards Secondary UI queries schema registry for data format based on schema present in packets Subscribe to telemetry + ML topics Display system diagnostics Display graphs Show ML inference output, species count, iceberg tracking, edna estimates, could be a web dashboard eg grafana DB writer queries schema registry for data format based on schema present in packets consumes telemetry stream/meta data from mqtt topic writes to postgres and influx or similar Replay engine runs anywhere reconstruct past missions from db publish to mqtt optionally stream timestamped synced video ML consumers subscribe to video data run inference tasks publish results back to mqtt archived processed annotations/images for training Archive s3/minio store for processed video","title":"Architecture"},{"location":"general/architecture/#responsibilities-of-services","text":"","title":"Responsibilities of services"},{"location":"general/architecture/#preprocesser","text":"parse raw sensor data/frames validate and annotate with mission_id, device, ingest_timestamp, schema_version, producer_id smooth or filter eg low pass compute derived metrics (velocity etc) publish to mqtt topics optionally provide rest endpoint for - /health \u2013 system heartbeat /schema \u2013 current telemetry schema (JSON Schema) /status \u2013 CPU/GPU/memory metrics","title":"Preprocesser"},{"location":"general/architecture/#mqtt-broker","text":"real time message bus for telemetry and status retain latest message for new subscribers (eg after ui disconnect) Topics such as rov/{rov_id}/{mission_id}/telemetry/{sensor} Allow multiple pub subs Bidirectional communication if necessary (might be for float)","title":"MQTT Broker"},{"location":"general/architecture/#video-ingest-service","text":"capture and encode video stream, stream low latency Avoid routing frames through mqtt, publish metadata to mqtt jetson nano, encode/decode and stream video using ffmpeg allow concurrent subscribers eg UI, recorder optionally provide rest endpoint for - /health \u2013 system heartbeat /schema \u2013 current telemetry schema (JSON Schema) /status \u2013 CPU/GPU/memory metrics","title":"Video ingest service"},{"location":"general/architecture/#schema-registry","text":"json schema with pydantic models accessed by fast api retrieve by version and allow ui to request a schema for decoding rather than hard coupling and redefining in all applications","title":"Schema registry"},{"location":"general/architecture/#ui","text":"queries schema registry for data format based on schema present in packets subscribe to cleaned topics via async mqtt clients decode video on seperate thread connect to video ingest service for low latency video show mission critical indicators display tasks lists, timers, alerts potentially allow limited controls input be able to render replay streams offload analysis to dashboards","title":"UI"},{"location":"general/architecture/#secondary-ui","text":"queries schema registry for data format based on schema present in packets Subscribe to telemetry + ML topics Display system diagnostics Display graphs Show ML inference output, species count, iceberg tracking, edna estimates, could be a web dashboard eg grafana","title":"Secondary UI"},{"location":"general/architecture/#db-writer","text":"queries schema registry for data format based on schema present in packets consumes telemetry stream/meta data from mqtt topic writes to postgres and influx or similar","title":"DB writer"},{"location":"general/architecture/#replay-engine","text":"runs anywhere reconstruct past missions from db publish to mqtt optionally stream timestamped synced video","title":"Replay engine"},{"location":"general/architecture/#ml-consumers","text":"subscribe to video data run inference tasks publish results back to mqtt archived processed annotations/images for training","title":"ML consumers"},{"location":"general/architecture/#archive","text":"s3/minio store for processed video","title":"Archive"},{"location":"general/development/","text":"Setting up your environment If you don't already have python installed, install it, eg from here Contribution Once you have installed python please install pip Then you will need to install poetry this is our dependency management system. The easiest way is probably via pipx . Once you have installed these run the following from the root folder cd <folder for project you want to work on> poetry install # for non mkdocs projects poetry install --no-root # for mkdocs project This installs all dependencies listed in pyproject.toml and locked in poetry.lock. It also creates a virtual environment for the project if one doesn\u2019t exist. Adding dependencies poetry add <package> # add a runtime dependency poetry add --dev <package> # add a dev dependency (for tests, linting, etc.) Then run poetry install # for non mkdocs projects poetry install --no-root # for mkdocs project Running a particular project Once inside the folder for the project if you have installed the dependencies run poetry run python3 <python file to run> # for python poetry run mkdocs serve # for mkdocs Using Pre-commit We use pre-commit to automatically run linters and formatters before committing code. This helps maintain code quality and consistency. From the root folder Install pre-commit (if not already installed): poetry add --dev pre-commit Install the Git hooks for the project: poetry run pre-commit install This sets up hooks that automatically run on git commit. Run pre-commit manually (optional, to check all files): poetry run pre-commit run --all-files If any hook fails, fix the issues, then commit again. Code quality Code is linted using the following tools: black - Code formatter (auto-formats code using defined rules in global pyproject.toml file) flake8 - Provides PEP8 linting, basic style & errors isort - Manages import order","title":"Development"},{"location":"general/development/#setting-up-your-environment","text":"If you don't already have python installed, install it, eg from here","title":"Setting up your environment"},{"location":"general/development/#contribution","text":"Once you have installed python please install pip Then you will need to install poetry this is our dependency management system. The easiest way is probably via pipx . Once you have installed these run the following from the root folder cd <folder for project you want to work on> poetry install # for non mkdocs projects poetry install --no-root # for mkdocs project This installs all dependencies listed in pyproject.toml and locked in poetry.lock. It also creates a virtual environment for the project if one doesn\u2019t exist.","title":"Contribution"},{"location":"general/development/#adding-dependencies","text":"poetry add <package> # add a runtime dependency poetry add --dev <package> # add a dev dependency (for tests, linting, etc.) Then run poetry install # for non mkdocs projects poetry install --no-root # for mkdocs project","title":"Adding dependencies"},{"location":"general/development/#running-a-particular-project","text":"Once inside the folder for the project if you have installed the dependencies run poetry run python3 <python file to run> # for python poetry run mkdocs serve # for mkdocs","title":"Running a particular project"},{"location":"general/development/#using-pre-commit","text":"We use pre-commit to automatically run linters and formatters before committing code. This helps maintain code quality and consistency. From the root folder Install pre-commit (if not already installed): poetry add --dev pre-commit Install the Git hooks for the project: poetry run pre-commit install This sets up hooks that automatically run on git commit. Run pre-commit manually (optional, to check all files): poetry run pre-commit run --all-files If any hook fails, fix the issues, then commit again.","title":"Using Pre-commit"},{"location":"general/development/#code-quality","text":"Code is linted using the following tools: black - Code formatter (auto-formats code using defined rules in global pyproject.toml file) flake8 - Provides PEP8 linting, basic style & errors isort - Manages import order","title":"Code quality"},{"location":"general/getting-started/","text":"Getting Started This guide walks you through setting up the full Team Bath ROV development environment from scratch. Prerequisites Install the following before proceeding: Tool Version Install link Python 3.11+ python.org/downloads Poetry latest python-poetry.org (install via pipx ) Node.js 20+ nodejs.org FFmpeg latest ffmpeg.org Git latest git-scm.com Verify your installs: python3 --version # 3.11+ poetry --version node --version # v20+ ffmpeg -version Clone Both Repos The project is split across two repositories: git clone https://github.com/Team-Bath-Hydrobotics/team-bath-rov-software.git git clone https://github.com/Team-Bath-Hydrobotics/team-bath-rov-secondary-ui.git Architecture Overview \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 team-bath-rov-secondary-ui \u2502 \u2502 (React + Vite) \u2502 \u2502 http://localhost:5173 \u2502 \u2502 \u2502 \u2502 Vite dev server proxies /api/* \u2502 \u2502 requests to the backend \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 team-bath-rov-software \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 photogrammetry-backend \u2502<\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 FastAPI \u2014 http://localhost:8100\u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 telemetry-processor \u2502 \u2502 \u2502 \u2502 video-processor \u2502 \u2502 \u2502 \u2502 packet-simulator \u2502 \u2502 \u2502 \u2502 machine-learning \u2502 \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The secondary UI is a React app served by Vite's dev server on port 5173 . Its Vite config includes a proxy rule that forwards any /api/* request to http://localhost:8100 , where the photogrammetry backend runs. This means during development both servers run independently, but the browser only talks to :5173 \u2014 Vite handles routing API calls to the backend, avoiding CORS issues. Other services in the monorepo (telemetry processor, video processor, etc.) communicate via MQTT and are designed to run on or near the ROV hardware. Per-Service Setup Photogrammetry Backend cd team-bath-rov-software/photogrammetry-backend pip install -e . uvicorn app.main:app --reload --port 8100 API: http://localhost:8100 Swagger docs: http://localhost:8100/docs The backend stores uploads in data/uploads/ and outputs in data/outputs/ (created automatically on first run). Secondary UI cd team-bath-rov-secondary-ui npm install npm run dev UI: http://localhost:5173 The UI should now be able to talk to the photogrammetry backend through the Vite proxy. Other Python Services Most Python services in the monorepo follow the same pattern: cd team-bath-rov-software/<service-folder> poetry install poetry run python3 <entrypoint>.py Check each service's README.md for the specific entrypoint. Docs Site cd team-bath-rov-software/docs-site poetry install --no-root poetry run mkdocs serve Docs will be served at http://localhost:8000 . Running Photogrammetry Backend + Secondary UI Together Terminal 1 \u2014 start the backend: bash cd team-bath-rov-software/photogrammetry-backend uvicorn app.main:app --reload --port 8100 Terminal 2 \u2014 start the UI: bash cd team-bath-rov-secondary-ui npm run dev Open http://localhost:5173 in your browser. The UI will proxy API requests to the backend automatically. Ports Reference Service Port Photogrammetry backend 8100 Secondary UI (Vite) 5173 Docs site (MkDocs) 8000 Troubleshooting Python version mismatch If you see errors about unsupported syntax or missing features, check your Python version: python3 --version The project requires Python 3.11+. If you have multiple versions installed, you may need to use python3.12 explicitly or manage versions with pyenv . Missing FFmpeg The video processor requires FFmpeg. If you get ffmpeg: command not found : macOS : brew install ffmpeg Ubuntu/Debian : sudo apt install ffmpeg Windows : Download from ffmpeg.org and add to your PATH Poetry not found Install Poetry via pipx (recommended): pipx install poetry Or via the official installer: curl -sSL https://install.python-poetry.org | python3 - CORS errors in the browser If you see CORS errors, make sure both servers are running and you're accessing the UI through http://localhost:5173 (not directly hitting the backend at :8100 from a browser page). Port already in use If a port is occupied, find and kill the process: lsof -i :8100 # or :5173 kill <PID>","title":"Getting Started"},{"location":"general/getting-started/#getting-started","text":"This guide walks you through setting up the full Team Bath ROV development environment from scratch.","title":"Getting Started"},{"location":"general/getting-started/#prerequisites","text":"Install the following before proceeding: Tool Version Install link Python 3.11+ python.org/downloads Poetry latest python-poetry.org (install via pipx ) Node.js 20+ nodejs.org FFmpeg latest ffmpeg.org Git latest git-scm.com Verify your installs: python3 --version # 3.11+ poetry --version node --version # v20+ ffmpeg -version","title":"Prerequisites"},{"location":"general/getting-started/#clone-both-repos","text":"The project is split across two repositories: git clone https://github.com/Team-Bath-Hydrobotics/team-bath-rov-software.git git clone https://github.com/Team-Bath-Hydrobotics/team-bath-rov-secondary-ui.git","title":"Clone Both Repos"},{"location":"general/getting-started/#architecture-overview","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 team-bath-rov-secondary-ui \u2502 \u2502 (React + Vite) \u2502 \u2502 http://localhost:5173 \u2502 \u2502 \u2502 \u2502 Vite dev server proxies /api/* \u2502 \u2502 requests to the backend \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 team-bath-rov-software \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 \u2502 photogrammetry-backend \u2502<\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 FastAPI \u2014 http://localhost:8100\u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 \u2502 telemetry-processor \u2502 \u2502 \u2502 \u2502 video-processor \u2502 \u2502 \u2502 \u2502 packet-simulator \u2502 \u2502 \u2502 \u2502 machine-learning \u2502 \u2502 \u2502 \u2502 ... \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The secondary UI is a React app served by Vite's dev server on port 5173 . Its Vite config includes a proxy rule that forwards any /api/* request to http://localhost:8100 , where the photogrammetry backend runs. This means during development both servers run independently, but the browser only talks to :5173 \u2014 Vite handles routing API calls to the backend, avoiding CORS issues. Other services in the monorepo (telemetry processor, video processor, etc.) communicate via MQTT and are designed to run on or near the ROV hardware.","title":"Architecture Overview"},{"location":"general/getting-started/#per-service-setup","text":"","title":"Per-Service Setup"},{"location":"general/getting-started/#photogrammetry-backend","text":"cd team-bath-rov-software/photogrammetry-backend pip install -e . uvicorn app.main:app --reload --port 8100 API: http://localhost:8100 Swagger docs: http://localhost:8100/docs The backend stores uploads in data/uploads/ and outputs in data/outputs/ (created automatically on first run).","title":"Photogrammetry Backend"},{"location":"general/getting-started/#secondary-ui","text":"cd team-bath-rov-secondary-ui npm install npm run dev UI: http://localhost:5173 The UI should now be able to talk to the photogrammetry backend through the Vite proxy.","title":"Secondary UI"},{"location":"general/getting-started/#other-python-services","text":"Most Python services in the monorepo follow the same pattern: cd team-bath-rov-software/<service-folder> poetry install poetry run python3 <entrypoint>.py Check each service's README.md for the specific entrypoint.","title":"Other Python Services"},{"location":"general/getting-started/#docs-site","text":"cd team-bath-rov-software/docs-site poetry install --no-root poetry run mkdocs serve Docs will be served at http://localhost:8000 .","title":"Docs Site"},{"location":"general/getting-started/#running-photogrammetry-backend-secondary-ui-together","text":"Terminal 1 \u2014 start the backend: bash cd team-bath-rov-software/photogrammetry-backend uvicorn app.main:app --reload --port 8100 Terminal 2 \u2014 start the UI: bash cd team-bath-rov-secondary-ui npm run dev Open http://localhost:5173 in your browser. The UI will proxy API requests to the backend automatically.","title":"Running Photogrammetry Backend + Secondary UI Together"},{"location":"general/getting-started/#ports-reference","text":"Service Port Photogrammetry backend 8100 Secondary UI (Vite) 5173 Docs site (MkDocs) 8000","title":"Ports Reference"},{"location":"general/getting-started/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"general/getting-started/#python-version-mismatch","text":"If you see errors about unsupported syntax or missing features, check your Python version: python3 --version The project requires Python 3.11+. If you have multiple versions installed, you may need to use python3.12 explicitly or manage versions with pyenv .","title":"Python version mismatch"},{"location":"general/getting-started/#missing-ffmpeg","text":"The video processor requires FFmpeg. If you get ffmpeg: command not found : macOS : brew install ffmpeg Ubuntu/Debian : sudo apt install ffmpeg Windows : Download from ffmpeg.org and add to your PATH","title":"Missing FFmpeg"},{"location":"general/getting-started/#poetry-not-found","text":"Install Poetry via pipx (recommended): pipx install poetry Or via the official installer: curl -sSL https://install.python-poetry.org | python3 -","title":"Poetry not found"},{"location":"general/getting-started/#cors-errors-in-the-browser","text":"If you see CORS errors, make sure both servers are running and you're accessing the UI through http://localhost:5173 (not directly hitting the backend at :8100 from a browser page).","title":"CORS errors in the browser"},{"location":"general/getting-started/#port-already-in-use","text":"If a port is occupied, find and kill the process: lsof -i :8100 # or :5173 kill <PID>","title":"Port already in use"},{"location":"general/git/","text":"This page documents how the team uses git. The team adopts a hybrid strategy that mixes github flow and release branches. General development Generally speaking as a developer to contribute you should do the following from the main branch git fetch git pull git checkout -b feature/<name of your new branch> Then make whatever changes you need, these should be small moduralised changes to make code reviews fast and to avoid large merge conflicts from divergent branches. Once you are happy with your changes run git add -A # adds all files or git add <file to add> # adds a specific file git commit -m \"<some comment about the code>\" git push origin feature/<name-of-your-new-branch> Then on github open a PR from to main This should follow the PR guidelines . Once your PR is approved merge it, run the following to keep your local main up to date git checkout main git pull origin main Then delete your feature branch locally and remotely if no longer needed git branch -d feature/<name-of-your-new-branch> git push origin --delete feature/<name-of-your-new-branch> Release branches When preparing a release, create a branch from main: git checkout -b release/<version> Only critical bug fixes and release preparation changes should go into the release branch. Once ready, merge the release branch back into main, then tag it: git checkout main git merge release/<version> git tag -a v<version> -m \"Release <version>\" Why we use release branches Stability: The main branch always reflects the latest stable release. By having a separate release branch, we can finalize and test the release without blocking ongoing feature development. Safe bug fixing: If a critical bug is found after the release branch is created, fixes can be applied directly to the release branch and then merged back into main, without disturbing features still in development. Clear versioning: Release branches make it easier to track versions and apply tags for production or deployment. Parallel development: We can continue working on new features in separate feature branches without affecting the release.","title":"Git"},{"location":"general/git/#general-development","text":"Generally speaking as a developer to contribute you should do the following from the main branch git fetch git pull git checkout -b feature/<name of your new branch> Then make whatever changes you need, these should be small moduralised changes to make code reviews fast and to avoid large merge conflicts from divergent branches. Once you are happy with your changes run git add -A # adds all files or git add <file to add> # adds a specific file git commit -m \"<some comment about the code>\" git push origin feature/<name-of-your-new-branch> Then on github open a PR from to main This should follow the PR guidelines . Once your PR is approved merge it, run the following to keep your local main up to date git checkout main git pull origin main Then delete your feature branch locally and remotely if no longer needed git branch -d feature/<name-of-your-new-branch> git push origin --delete feature/<name-of-your-new-branch>","title":"General development"},{"location":"general/git/#release-branches","text":"When preparing a release, create a branch from main: git checkout -b release/<version> Only critical bug fixes and release preparation changes should go into the release branch. Once ready, merge the release branch back into main, then tag it: git checkout main git merge release/<version> git tag -a v<version> -m \"Release <version>\"","title":"Release branches"},{"location":"general/git/#why-we-use-release-branches","text":"Stability: The main branch always reflects the latest stable release. By having a separate release branch, we can finalize and test the release without blocking ongoing feature development. Safe bug fixing: If a critical bug is found after the release branch is created, fixes can be applied directly to the release branch and then merged back into main, without disturbing features still in development. Clear versioning: Release branches make it easier to track versions and apply tags for production or deployment. Parallel development: We can continue working on new features in separate feature branches without affecting the release.","title":"Why we use release branches"},{"location":"general/pr/","text":"PR guidance Keep PRs small and focused. Always pull the latest main before creating a branch. Run pre-commit hooks locally before committing, this can be automated as outlined in the development page . Ensure that all functionality is tested before merging. How to PR review When reviewing a PR, follow these steps: Confirm that it addresses a specific task or issue. Look for adherence to coding standards (formatting, naming, structure). Verify that the code works as intended. Check for potential issues with the code or potential points of conflict Ensure that changes are modular and don\u2019t introduce unnecessary dependencies. Comment constructively, and ask clarifying questions rather than making assumptions.","title":"Pull Requests"},{"location":"general/pr/#pr-guidance","text":"Keep PRs small and focused. Always pull the latest main before creating a branch. Run pre-commit hooks locally before committing, this can be automated as outlined in the development page . Ensure that all functionality is tested before merging.","title":"PR guidance"},{"location":"general/pr/#how-to-pr-review","text":"When reviewing a PR, follow these steps: Confirm that it addresses a specific task or issue. Look for adherence to coding standards (formatting, naming, structure). Verify that the code works as intended. Check for potential issues with the code or potential points of conflict Ensure that changes are modular and don\u2019t introduce unnecessary dependencies. Comment constructively, and ask clarifying questions rather than making assumptions.","title":"How to PR review"},{"location":"general/roadmap/","text":"The team has a few milestones, which form our roadmap. 2025 Be able to run the original UI with the rover Verify photosphere works Create image recongition pipeline reduce load on pyqt main thread implement preprocessor implement schema registry Create internal docs site mk docs Create external sponsorships site github pages git versioning/release strategy/ code review strategy 2026 Build out the architecture outlined here Instrumentation of all services + grafana monitoring to see latency etc Beyond 2026 Think about wether we want to move towards something like ROS2 Think about how we can enable engineers, eg helping them run simulations etc Think about how we can enable pilots to train without needing the ROV Think about how we can automate, cost analysis, mission summary generation etc, eg help non engineering teams","title":"Roadmap"},{"location":"general/roadmap/#2025","text":"Be able to run the original UI with the rover Verify photosphere works Create image recongition pipeline reduce load on pyqt main thread implement preprocessor implement schema registry Create internal docs site mk docs Create external sponsorships site github pages git versioning/release strategy/ code review strategy","title":"2025"},{"location":"general/roadmap/#2026","text":"Build out the architecture outlined here Instrumentation of all services + grafana monitoring to see latency etc","title":"2026"},{"location":"general/roadmap/#beyond-2026","text":"Think about wether we want to move towards something like ROS2 Think about how we can enable engineers, eg helping them run simulations etc Think about how we can enable pilots to train without needing the ROV Think about how we can automate, cost analysis, mission summary generation etc, eg help non engineering teams","title":"Beyond 2026"},{"location":"other/25-26/team/","text":"Software team Lead: Ayda - github:ayda-yazdani Members: Max Byng-Maddick - gihub:mbm60-max Varniethan Ketheeswaran - github: Hugh Barker - github: Alex Dent - github:skalex05 Rohan - github: Sofia - github:","title":"25-26 Team"},{"location":"other/25-26/team/#software-team-lead","text":"Ayda - github:ayda-yazdani","title":"Software team Lead:"},{"location":"other/25-26/team/#members","text":"Max Byng-Maddick - gihub:mbm60-max Varniethan Ketheeswaran - github: Hugh Barker - github: Alex Dent - github:skalex05 Rohan - github: Sofia - github:","title":"Members:"},{"location":"projects/db-writer/db-writer/","text":"Pages in this folder should be used for documenting the db-writer tool","title":"DB Writer"},{"location":"projects/preprocessor/preprocessor/","text":"Pages in this folder should be used for documenting the pre-processing tool","title":"Preprocessor"},{"location":"projects/schema-registry/schema-registry/","text":"Pages in this folder should be used for documenting the schema registry","title":"Schema Registry"},{"location":"projects/ui/ui/","text":"Pages in this folder should be used for documenting the pilot ui","title":"UI"}]}